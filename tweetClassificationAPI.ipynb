{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic classification with proprietary models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class SentimentAnalyzer(ABC):\n",
    "    def __init__(self,model: str, prompt: str):\n",
    "        self._setup(model, prompt)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _setup(self):\n",
    "        \"\"\"Setup API credentials and model configuration\"\"\"\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _get_raw_sentiment(self, text: str) -> str:\n",
    "        \"\"\"Get raw sentiment from the API\"\"\"\n",
    "        pass\n",
    "\n",
    "    def analyze_sentiment(self, text: str) -> str:\n",
    "        \"\"\"Analyze sentiment of the given text. Returns 'positive', 'negative', or 'neutral'.\"\"\"\n",
    "        try:\n",
    "            sentiment = self._get_raw_sentiment(text).strip().lower()\n",
    "            return self._validate_sentiment(sentiment)\n",
    "        except Exception as e:\n",
    "            print(f\"{self.__class__.__name__} Error: {e}\")\n",
    "            return 'neutral'\n",
    "\n",
    "    def _validate_sentiment(self, sentiment: str) -> str:\n",
    "        \"\"\"Validate and normalize sentiment response\"\"\"\n",
    "        return sentiment if sentiment in ['positive', 'negative', 'neutral'] else 'neutral'\n",
    "\n",
    "class OpenAIAnalyzer(SentimentAnalyzer):\n",
    "    def _setup(self,model: str, prompt: str):\n",
    "        self.model = model \n",
    "        self.prompt = prompt\n",
    "    def _get_raw_sentiment(self, text: str) -> str:\n",
    "        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.prompt},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=10\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"tweet_eval\", \"sentiment\")\n",
    "\n",
    "# Convert to pandas DataFrame for easier handling\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "# Take a subset for testing (to manage API costs)\n",
    "sample_size = 100\n",
    "train_sample = train_df.sample(n=sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt variants for sentiment classification\n",
    "prompts = [\n",
    "    \"You are a sentiment analysis assistant. Classify the sentiment of the given tweet as 'positive', 'neutral', or 'negative'. Reply with only one word.\",\n",
    "    \"Analyze the emotional tone of this tweet and categorize it as 'positive', 'neutral', or 'negative'. Provide only a one-word response.\",\n",
    "    \"Determine whether the following tweet expresses a 'positive', 'neutral', or 'negative' sentiment. Respond with a single word only.\",\n",
    "    \"As a sentiment classifier, evaluate this tweet and label it as 'positive', 'neutral', or 'negative'. Your response should be exactly one word.\",\n",
    "    \"Read this tweet and identify its sentiment. Is it 'positive', 'neutral', or 'negative'? Answer with just one word.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TweetEval dataset...\n",
      "Processing 100 tweets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to tweet_sentiment_results_gpt-3.5-turbo_promptix_2.csv\n",
      "\n",
      "Sentiment Distribution:\n",
      "predicted_sentiment_gpt-3.5-turbo_promptix_2\n",
      "positive    54\n",
      "negative    25\n",
      "neutral     21\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load TweetEval dataset\n",
    "model = \"gpt-3.5-turbo\" #\"gpt-4o-mini\" #\n",
    "prompt_ix = 2\n",
    "\n",
    "analyzer = OpenAIAnalyzer(model=model, prompt=prompts[prompt_ix])\n",
    "print(\"Loading TweetEval dataset...\")\n",
    "\n",
    "\n",
    "print(f\"Processing {sample_size} tweets...\")\n",
    "\n",
    "# Add sentiment predictions\n",
    "sentiments = []\n",
    "for tweet in tqdm(train_sample['text']):\n",
    "    sentiment = analyzer.analyze_sentiment(tweet)\n",
    "    sentiments.append(sentiment)\n",
    "    # Add a small delay to avoid rate limits\n",
    "    time.sleep(0.1)\n",
    "\n",
    "column_name = f'predicted_sentiment_{model}_promptix_{prompt_ix}'\n",
    "train_sample[column_name] = sentiments\n",
    "\n",
    "# Save results\n",
    "output_file = f'tweet_sentiment_results_{model}_promptix_{prompt_ix}.csv'\n",
    "train_sample.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Print some statistics\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(train_sample[column_name].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_sentiment_gpt-4o-mini_promptix_2</th>\n",
       "      <th>predicted_sentiment_gpt-3.5-turbo_promptix_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>I forgot all about Ice Cube being in the movie...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26433</th>\n",
       "      <td>playoffs are finally set. Chardon plays warren...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33669</th>\n",
       "      <td>Are we just going to ignore the fact that Ice ...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33013</th>\n",
       "      <td>If you live in the South Orlando area\\u002c be...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13399</th>\n",
       "      <td>First record of Colin Baker at the BBC: BBC2 s...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "11449  I forgot all about Ice Cube being in the movie...      0   \n",
       "26433  playoffs are finally set. Chardon plays warren...      1   \n",
       "33669  Are we just going to ignore the fact that Ice ...      1   \n",
       "33013  If you live in the South Orlando area\\u002c be...      1   \n",
       "13399  First record of Colin Baker at the BBC: BBC2 s...      1   \n",
       "\n",
       "      predicted_sentiment_gpt-4o-mini_promptix_2  \\\n",
       "11449                                    neutral   \n",
       "26433                                    neutral   \n",
       "33669                                   negative   \n",
       "33013                                   positive   \n",
       "13399                                    neutral   \n",
       "\n",
       "      predicted_sentiment_gpt-3.5-turbo_promptix_2  \n",
       "11449                                      neutral  \n",
       "26433                                     positive  \n",
       "33669                                     negative  \n",
       "33013                                     positive  \n",
       "13399                                     positive  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 64.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print accuracy\n",
    "def calculate_accuracy(train_sample, column_name):\n",
    "    id2label = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "    correct_predictions = [label2id[train_sample[column_name].iloc[i]] == train_sample['label'].iloc[i] for i in range(sample_size)]\n",
    "    accuracy = sum(correct_predictions) / sample_size\n",
    "    print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "calculate_accuracy(train_sample, column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing batch processing data...\n",
      "Batch requests saved to batch_sentiment_requests2.jsonl\n",
      "Total requests prepared: 100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Prepare batch processing data\n",
    "print(\"Preparing batch processing data...\")\n",
    "\n",
    "\n",
    "def get_batch_requests(model: str, train_sample, prompt: str):\n",
    "    # Create a list to store request objects\n",
    "    batch_requests = []\n",
    "\n",
    "    # Loop through the sample tweets to create batch requests\n",
    "    for idx, tweet in enumerate(train_sample['text']):\n",
    "        request = {\n",
    "            \"custom_id\": f\"tweet-{idx}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": model,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\":  prompt},\n",
    "                    {\"role\": \"user\", \"content\": tweet}\n",
    "                ],\n",
    "                \"max_tokens\": 10\n",
    "            }\n",
    "        }\n",
    "        batch_requests.append(request)\n",
    "    return batch_requests\n",
    "\n",
    "\n",
    "\n",
    "batch_requests = get_batch_requests(model, train_sample, prompts[prompt_ix])\n",
    "# Write requests to a JSONL file\n",
    "output_jsonl = 'batch_sentiment_requests2.jsonl'\n",
    "with open(output_jsonl, 'w') as f:\n",
    "    for request in batch_requests:\n",
    "        f.write(json.dumps(request) + '\\n')\n",
    "\n",
    "print(f\"Batch requests saved to {output_jsonl}\")\n",
    "print(f\"Total requests prepared: {len(batch_requests)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-T2gV1JgMG2urmv8vr6E3fV', bytes=45136, created_at=1744218995, filename='batch_sentiment_requests2.jsonl', object='file', purpose='batch', status='processed', expires_at=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(\"batch_sentiment_requests2.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67f6ab9098908190968c0f4379fbf66f', completion_window='24h', created_at=1744219024, endpoint='/v1/chat/completions', input_file_id='file-T2gV1JgMG2urmv8vr6E3fV', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1744305424, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Sentiment analysis of tweets'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"Sentiment analysis of tweets\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = client.batches.retrieve('batch_67f6ab9098908190968c0f4379fbf66f')\n",
    "batch.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(id='batch_67f6ab9098908190968c0f4379fbf66f', completion_window='24h', created_at=1744219024, endpoint='/v1/chat/completions', input_file_id='file-T2gV1JgMG2urmv8vr6E3fV', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1744219054, error_file_id=None, errors=None, expired_at=None, expires_at=1744305424, failed_at=None, finalizing_at=1744219048, in_progress_at=1744219025, metadata={'description': 'Sentiment analysis of tweets'}, output_file_id='file-ApLMS99TktKPGedJpG71YC', request_counts=BatchRequestCounts(completed=100, failed=0, total=100)),\n",
       " Batch(id='batch_67f6a87784ec8190bc1b49a896919589', completion_window='24h', created_at=1744218231, endpoint='/v1/chat/completions', input_file_id='file-XRBDjmKoo2gy41pDrquwmm', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1744218325, error_file_id=None, errors=None, expired_at=None, expires_at=1744304631, failed_at=None, finalizing_at=1744218317, in_progress_at=1744218232, metadata={'description': 'Sentiment analysis of tweets'}, output_file_id='file-GW9WhvpmqkC6aecCEGJfUn', request_counts=BatchRequestCounts(completed=100, failed=0, total=100))]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.list(limit=10).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed JSONL data\n",
      "Number of records: 100\n",
      "\n",
      "Sample record:\n",
      "{\n",
      "  \"id\": \"batch_req_67f6a8cd91348190adc964ca1b7e4a2d\",\n",
      "  \"custom_id\": \"tweet-0\",\n",
      "  \"response\": {\n",
      "    \"status_code\": 200,\n",
      "    \"request_id\": \"42bf69f07acef7354529b5a5bea04cab\",\n",
      "    \"body\": {\n",
      "      \"id\": \"chatcmpl-BKT9DGbsiBCwYxMNFjezcGzqYUNqm\",\n",
      "      \"object\": \"chat.completion\",\n",
      "      \"created\": 1744218303,\n",
      "      \"model\": \"gpt-3.5-turbo-0125\",\n",
      "      \"choices\": [\n",
      "        {\n",
      "          \"index\": 0,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"neutral\",\n",
      "            \"refusal\": null,\n",
      "            \"annotations\": []\n",
      "          },\n",
      "          \"logprobs\": null,\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      ],\n",
      "      \"usage\": {\n",
      "        \"prompt_tokens\": 61,\n",
      "        \"completion_tokens\": 2,\n",
      "        \"total_tokens\": 63,\n",
      "        \"prompt_tokens_details\": {\n",
      "          \"cached_tokens\": 0,\n",
      "          \"audio_tokens\": 0\n",
      "        },\n",
      "        \"completion_tokens_details\": {\n",
      "          \"reasoning_tokens\": 0,\n",
      "          \"audio_tokens\": 0,\n",
      "          \"accepted_prediction_tokens\": 0,\n",
      "          \"rejected_prediction_tokens\": 0\n",
      "        }\n",
      "      },\n",
      "      \"service_tier\": \"default\",\n",
      "      \"system_fingerprint\": null\n",
      "    }\n",
      "  },\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_response = client.files.content(\"file-GW9WhvpmqkC6aecCEGJfUn\")\n",
    "# Get the outputs from the file response\n",
    "file_content = file_response.text\n",
    "\n",
    "# Parse the JSON content\n",
    "try:\n",
    "    # If the content is a single JSON object\n",
    "    parsed_data = json.loads(file_content)\n",
    "    print(\"Successfully parsed JSON data\")\n",
    "    print(f\"Number of records: 1\")\n",
    "    \n",
    "except json.JSONDecodeError:\n",
    "    # If the content is JSONL (multiple JSON objects, one per line)\n",
    "    parsed_data = []\n",
    "    for line in file_content.strip().split('\\n'):\n",
    "        try:\n",
    "            parsed_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing line: {e}\")\n",
    "    \n",
    "    print(\"Successfully parsed JSONL data\")\n",
    "    print(f\"Number of records: {len(parsed_data)}\")\n",
    "\n",
    "# Display a sample of the parsed data\n",
    "if parsed_data:\n",
    "    if isinstance(parsed_data, list):\n",
    "        print(\"\\nSample record:\")\n",
    "        print(json.dumps(parsed_data[0], indent=2))\n",
    "    else:\n",
    "        print(\"\\nParsed data:\")\n",
    "        print(json.dumps(parsed_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract predictions from the batch output\n",
    "predictions = []\n",
    "for item in parsed_data:\n",
    "    # Extract the sentiment prediction from the model's response\n",
    "    response_content = item['response']['body']['choices'][0]['message']['content']\n",
    "    \n",
    "    # Determine the sentiment from the response\n",
    "    sentiment = None\n",
    "    response_lower = response_content.lower()\n",
    "    if 'positive' in response_lower:\n",
    "        sentiment = 'positive'\n",
    "    elif 'negative' in response_lower:\n",
    "        sentiment = 'negative'\n",
    "    elif 'neutral' in response_lower:\n",
    "        sentiment = 'neutral'\n",
    "    else:\n",
    "        sentiment = 'unknown'\n",
    "    \n",
    "    predictions.append({\n",
    "        'id': item['custom_id'].split('-')[1], # !!! the response can have different order as the request\n",
    "        'predicted_sentiment': sentiment\n",
    "    })\n",
    "\n",
    "predictions = [pred['predicted_sentiment'] for pred in sorted(predictions, key=lambda x: int(x['id']))]\n",
    "predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 64.00%\n"
     ]
    }
   ],
   "source": [
    "column_name = f'predicted_sentiment_{model}_promptix_{prompt_ix}_batch'\n",
    "train_sample[column_name] = sentiments\n",
    "calculate_accuracy(train_sample, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
